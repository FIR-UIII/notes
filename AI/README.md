https://medium.com/@deepujain/how-to-build-a-local-ai-like-chatgpt-using-deepseek-r1-and-open-webui-c043badd4c07

# Проработка архитектуры:

### Требования:
безопасность - использование локальной LLM, все данные не выходят за контур localhost
мастабируемость - система должна иметь возможность полнять другие агенты в инфраструктуру
практичность - агенты должны выполнять свою работу не создавать доп.нагрузку на человека т.е. работа ради работы

# Шаги
demo - создание простого агента для анализа функциональности и обогащения базы знаний. Смена фреймворка или требований
mvp - создание первого прототипа агента для решения задач AppSec, может не решать задачи.
test - создание готового прототипа способного решать задачи AppSec

# Подходы реализации
### Конструктор AI (Low code)
|+   | -   |
|----|-----|
|Быстрое прототипирование: Визуальные конструкторы (drag-and-drop)|Ограниченная гибкость: Сложно реализовать кастомную логику или сложные мультиагентные сценарии|
|Доступность: Подходят для бизнес-аналитиков или небольших команд без глубоких знаний ML.|Зависимость от экосистемы: Интеграции с нейросетевыми моделями (например, GPT-4) часто требуют доплат или ограничены проприетарными API|
|Автоматизация рабочих процессов: Идеальны для рутинных задач|n8n слабо подходит для создания автономных агентов с динамическим принятием решений|

Примеры:<br>
n8s https://github.com/n8n-io/self-hosted-ai-starter-kit <br>
https://www.youtube.com/watch?v=MGaR7i35KhA&list=WL&index=3

### Python-Фреймворки 
|+   | -   |
|----|-----|
|Полный контроль: Возможность тонкой настройки архитектуры агента|ысокий порог входа: Требуются навыки Python и понимание ML|
|Богатые возможности: Поддержка мультиагентных систем (в AutoGen агенты взаимодействуют как коллеги), RAG (LangChain), генерации кода (SmolAgents)|Сложность отладки: Ошибки в цепочках агентов трудно локализовать|
|Cообщество и экосистема: LangChain и LlamaIndex предоставляют готовые решения для интеграции|Инфраструктурные затраты: Необходимо развертывать и масштабировать серверы|

Примеры:<br>
* LangChain https://github.com/langchain-ai/langchain
* LlamaIndex https://github.com/run-llama/llama_index
* AutoGen https://github.com/microsoft/autogen
* CrewAI https://github.com/crewAIInc/crewAI
* OpenAI https://github.com/openai/openai-agents-python

# Анализ
Выбор техстека
Платформа для создания AI agents

### RAG
Подход где перед каждым вызовом LLM через промпт - мы достает информацию из БД для создания контекста.
Когда использовать: в датасете может не быть нужной информации и мы хотим дать контекст. Ограничение LLM - оно не может загрузить в себя больше информации чем определенный размер памяти ей позволяет context window, из за чего возникает путаница, галлюцинации. или данные в LLM устарели.

### MCP server - client
MCP server - коннектор связанный с определенным источником, имеет с ним работать так, чтобы и MCP client мог делать запросы
MCP client - связывает MCP server и LLM / agent AI

### LLM self-hosted
https://github.com/bentoml/OpenLLM
https://github.com/deepseek-ai/DeepSeek-R1
https://ollama.com/download


https://github.com/NVIDIA-AI-Blueprints/vulnerability-analysis/tree/main